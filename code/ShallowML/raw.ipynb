{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "process pcap data for get traditional baseline\n",
    "label.pcap -> raw hex code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import scapy.all as scapy\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('LLM4Traffic/code/Traditional')\n",
    "\n",
    "logging.basicConfig(       \n",
    "    level=logging.INFO,            \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  \n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/raw.log', mode='w'),  \n",
    "        logging.StreamHandler()          \n",
    "    ],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'LLM4Traffic/polishedns/ustc-binary'\n",
    "output_path = 'LLM4Traffic/code/Traditional/datasets/polishedns/ustc-binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_packet(packet):\n",
    "    if packet.haslayer(scapy.Ether):\n",
    "        packet = packet[scapy.Ether].payload\n",
    "\n",
    "    if packet.haslayer(scapy.IP):\n",
    "        packet[scapy.IP].src = \"0.0.0.0\"\n",
    "        packet[scapy.IP].dst = \"0.0.0.0\"\n",
    "    elif packet.haslayer('IPv6'):\n",
    "        packet['IPv6'].src = \"::\"\n",
    "        packet['IPv6'].dst = \"::\"\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    if packet.haslayer(scapy.UDP):\n",
    "        packet[scapy.UDP].sport = 0  # 设置源端口为0\n",
    "        packet[scapy.UDP].dport = 0  # 设置目的端口为0\n",
    "        packet[scapy.UDP].remove_payload()  # 删除 UDP 载荷\n",
    "    elif packet.haslayer(scapy.TCP):\n",
    "        packet[scapy.TCP].sport = 0  # 设置源端口为0\n",
    "        packet[scapy.TCP].dport = 0  # 设置目的端口为0\n",
    "        packet[scapy.TCP].remove_payload()  # 删除 TCP 载荷\n",
    "    \n",
    "    return packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 21:37:45,221 - root - INFO - Processing test.pcap\n",
      "2024-12-15 21:38:20,236 - root - INFO - Processing train_val_split_2\n",
      "2024-12-15 21:38:20,884 - root - INFO - Processing train_val_split_2 train.parquet\n",
      "2024-12-15 21:38:21,021 - root - INFO - Processing train_val_split_2 val.pcap\n",
      "2024-12-15 21:38:29,900 - root - INFO - Processing train_val_split_2 train.pcap\n",
      "2024-12-15 21:39:13,601 - root - INFO - Processing train_val_split_2 val.parquet\n",
      "2024-12-15 21:39:14,031 - root - INFO - Processing train_val_split_0\n",
      "2024-12-15 21:39:14,044 - root - INFO - Processing train_val_split_0 train.parquet\n",
      "2024-12-15 21:39:14,092 - root - INFO - Processing train_val_split_0 val.pcap\n",
      "2024-12-15 21:39:22,871 - root - INFO - Processing train_val_split_0 train.pcap\n",
      "2024-12-15 21:40:06,478 - root - INFO - Processing train_val_split_0 val.parquet\n",
      "2024-12-15 21:40:07,118 - root - INFO - Processing train_val_split_1\n",
      "2024-12-15 21:40:07,335 - root - INFO - Processing train_val_split_1 train.parquet\n",
      "2024-12-15 21:40:07,358 - root - INFO - Processing train_val_split_1 val.pcap\n",
      "2024-12-15 21:40:16,024 - root - INFO - Processing train_val_split_1 train.pcap\n",
      "2024-12-15 21:40:53,587 - root - INFO - Processing train_val_split_1 val.parquet\n",
      "2024-12-15 21:40:53,597 - root - INFO - Processing test.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "# get how many features/ip flags/tcp flags/.. in the dataset\n",
    "# # file/{test.pcap} or file/{train_val_split_0}/{train.pcap}\n",
    "max_payload_length = 0\n",
    "\n",
    "for type in os.listdir(dataset_path):\n",
    "    logger.info(f'Processing {type}')\n",
    "\n",
    "    if 'test' in type:\n",
    "        if 'pcap' in type:\n",
    "            packets =  scapy.PcapReader(f'{dataset_path}/{type}')\n",
    "            for id, packet in enumerate(packets):\n",
    "                # only require ip header and transportaion layer\n",
    "                packet = clean_packet(packet)\n",
    "                if packet == 0:\n",
    "                    continue\n",
    "\n",
    "                hex_str = bytes(packet).hex()\n",
    "                if len(hex_str) > max_payload_length:\n",
    "                    max_payload_length = len(hex_str)\n",
    "        continue\n",
    "\n",
    "    for class_id, file_name in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "        logger.info(f'Processing {type} {file_name}')\n",
    "        if 'pcap' not in file_name:\n",
    "            continue\n",
    "\n",
    "        packets =  scapy.PcapReader(f'{dataset_path}/{type}/{file_name}')\n",
    "        for id, packet in enumerate(packets):\n",
    "            # only require ip header and transportaion layer\n",
    "            packet = clean_packet(packet)\n",
    "            if packet == 0:\n",
    "                continue\n",
    "\n",
    "            hex_str = bytes(packet).hex()\n",
    "            if len(hex_str) > max_payload_length:\n",
    "                max_payload_length = len(hex_str)\n",
    "            \n",
    "print(max_payload_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 09:23:55,224 - root - INFO - Processing train_val_split_2\n",
      "2025-01-06 09:23:55,225 - root - INFO - Processing train_val_split_2 train\n",
      "2025-01-06 09:24:37,064 - root - INFO - Processing train_val_split_2 val\n",
      "2025-01-06 09:24:42,053 - root - INFO - Processing train_val_split_0\n",
      "2025-01-06 09:24:42,055 - root - INFO - Processing train_val_split_0 train\n",
      "2025-01-06 09:25:23,823 - root - INFO - Processing train_val_split_0 val\n",
      "2025-01-06 09:25:28,906 - root - INFO - Processing test\n",
      "2025-01-06 09:25:28,908 - root - INFO - Processing test malware.pcap\n",
      "2025-01-06 09:27:05,395 - root - INFO - Processing test benign.pcap\n",
      "2025-01-06 09:29:46,850 - root - INFO - Processing train_val_split_1\n",
      "2025-01-06 09:29:46,854 - root - INFO - Processing train_val_split_1 train\n",
      "2025-01-06 09:30:28,056 - root - INFO - Processing train_val_split_1 val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "# get how many features/ip flags/tcp flags/.. in the dataset\n",
    "# # file/test/{test.pcap} or file/train_val_split_0/{train/val}/.pcap\n",
    "max_payload_length = 0\n",
    "\n",
    "for type in os.listdir(dataset_path):\n",
    "    logger.info(f'Processing {type}')\n",
    "\n",
    "    if 'test' == type:\n",
    "        for class_id, file_name in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "            if 'pcap' in file_name:\n",
    "                logger.info(f'Processing {type} {file_name}')\n",
    "\n",
    "                packets =  scapy.PcapReader(f'{dataset_path}/{type}/{file_name}')\n",
    "                for id, packet in enumerate(packets):\n",
    "                    # only require ip header and transportaion layer\n",
    "                    packet = clean_packet(packet)\n",
    "                    if packet == 0:\n",
    "                        continue\n",
    "\n",
    "                    hex_str = bytes(packet).hex()\n",
    "                    if len(hex_str) > max_payload_length:\n",
    "                        max_payload_length = len(hex_str)\n",
    "    else:\n",
    "        for class_id, folder in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "            logger.info(f'Processing {type} {folder}')\n",
    "\n",
    "            for file_name in os.listdir(f'{dataset_path}/{type}/{folder}'):\n",
    "                if 'pcap' in file_name:\n",
    "                    packets =  scapy.PcapReader(f'{dataset_path}/{type}/{folder}/{file_name}')\n",
    "                    for id, packet in enumerate(packets):\n",
    "                        # only require ip header and transportaion layer\n",
    "                        packet = clean_packet(packet)\n",
    "                        if packet == 0:\n",
    "                            continue\n",
    "\n",
    "                        hex_str = bytes(packet).hex()\n",
    "                        if len(hex_str) > max_payload_length:\n",
    "                            max_payload_length = len(hex_str)\n",
    "            \n",
    "print(max_payload_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 07:20:13,746 - root - INFO - Processing train_val_split_2\n",
      "2025-01-02 07:20:13,748 - root - INFO - Processing train_val_split_2 train\n",
      "2025-01-02 07:20:13,748 - root - INFO - Processing train_val_split_2 val\n",
      "2025-01-02 07:20:13,749 - root - INFO - Processing train_val_split_0\n",
      "2025-01-02 07:20:13,750 - root - INFO - Processing train_val_split_0 train\n",
      "2025-01-02 07:20:13,751 - root - INFO - Processing train_val_split_0 val\n",
      "2025-01-02 07:20:13,751 - root - INFO - Processing test\n",
      "2025-01-02 07:20:13,752 - root - INFO - Processing train_val_split_1\n",
      "2025-01-02 07:20:13,753 - root - INFO - Processing train_val_split_1 train\n",
      "2025-01-02 07:20:13,753 - root - INFO - Processing train_val_split_1 val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# # file/{test.pcap} or file/{train_val_split_0}/{train.pcap}\n",
    "byte_vocab = set()\n",
    "\n",
    "for type in os.listdir(dataset_path):\n",
    "    logger.info(f'Processing {type}')\n",
    "\n",
    "    if 'test' in type:\n",
    "        if 'pcap' in type:\n",
    "            packets =  scapy.PcapReader(f'{dataset_path}/{type}')\n",
    "            for id, packet in enumerate(packets):\n",
    "                # only require ip header and transportaion layer\n",
    "                packet = clean_packet(packet)\n",
    "                if packet == 0:\n",
    "                    continue\n",
    "\n",
    "                hex_str = bytes(packet).hex()\n",
    "                if len(hex_str) < max_payload_length:\n",
    "                    hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "                hex_array = [hex_str[i:i+4] for i in range(0, len(hex_str), 4)]\n",
    "\n",
    "                byte_vocab.update(hex_array)\n",
    "        continue\n",
    "\n",
    "    for class_id, file_name in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "        logger.info(f'Processing {type} {file_name}')\n",
    "        if 'pcap' not in file_name:\n",
    "            continue\n",
    "\n",
    "        packets =  scapy.PcapReader(f'{dataset_path}/{type}/{file_name}')\n",
    "        for id, packet in enumerate(packets):\n",
    "            # only require ip header and transportaion layer\n",
    "            packet = clean_packet(packet)\n",
    "            if packet == 0:\n",
    "                continue\n",
    "\n",
    "            hex_str = bytes(packet).hex()\n",
    "            if len(hex_str) < max_payload_length:\n",
    "                hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "            hex_array = [hex_str[i:i+4] for i in range(0, len(hex_str), 4)]\n",
    "\n",
    "            byte_vocab.update(hex_array)\n",
    "\n",
    "byte_list = list(byte_vocab)\n",
    "print(len(byte_list))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 09:30:59,612 - root - INFO - Processing train_val_split_2\n",
      "2025-01-06 09:30:59,614 - root - INFO - Processing train_val_split_2 train\n",
      "2025-01-06 09:31:41,884 - root - INFO - Processing train_val_split_2 val\n",
      "2025-01-06 09:31:46,931 - root - INFO - Processing train_val_split_0\n",
      "2025-01-06 09:31:46,935 - root - INFO - Processing train_val_split_0 train\n",
      "2025-01-06 09:32:28,891 - root - INFO - Processing train_val_split_0 val\n",
      "2025-01-06 09:32:34,092 - root - INFO - Processing test\n",
      "2025-01-06 09:32:34,094 - root - INFO - Processing test malware.pcap\n",
      "2025-01-06 09:34:12,872 - root - INFO - Processing test benign.pcap\n",
      "2025-01-06 09:36:57,296 - root - INFO - Processing train_val_split_1\n",
      "2025-01-06 09:36:57,298 - root - INFO - Processing train_val_split_1 train\n",
      "2025-01-06 09:37:39,427 - root - INFO - Processing train_val_split_1 val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65536\n"
     ]
    }
   ],
   "source": [
    "# # file/test/{test.pcap} or file/train_val_split_0/{train/val}/.pcap\n",
    "byte_vocab = set()\n",
    "\n",
    "for type in os.listdir(dataset_path):\n",
    "    logger.info(f'Processing {type}')\n",
    "\n",
    "    if 'test' == type:\n",
    "        for class_id, file_name in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "            if 'pcap' in file_name:\n",
    "                logger.info(f'Processing {type} {file_name}')\n",
    "\n",
    "                packets =  scapy.PcapReader(f'{dataset_path}/{type}/{file_name}')\n",
    "                for id, packet in enumerate(packets):\n",
    "                    # only require ip header and transportaion layer\n",
    "                    packet = clean_packet(packet)\n",
    "                    if packet == 0:\n",
    "                        continue\n",
    "\n",
    "                    hex_str = bytes(packet).hex()\n",
    "                    if len(hex_str) < max_payload_length:\n",
    "                        hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "                    hex_array = [hex_str[i:i+4] for i in range(0, len(hex_str), 4)]\n",
    "\n",
    "                    byte_vocab.update(hex_array)\n",
    "    else:\n",
    "        for class_id, folder in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "            logger.info(f'Processing {type} {folder}')\n",
    "\n",
    "            for file_name in os.listdir(f'{dataset_path}/{type}/{folder}'):\n",
    "                if 'pcap' in file_name:\n",
    "                    packets =  scapy.PcapReader(f'{dataset_path}/{type}/{folder}/{file_name}')\n",
    "                    for id, packet in enumerate(packets):\n",
    "                        # only require ip header and transportaion layer\n",
    "                        packet = clean_packet(packet)\n",
    "                        if packet == 0:\n",
    "                            continue\n",
    "\n",
    "                        hex_str = bytes(packet).hex()\n",
    "                        if len(hex_str) < max_payload_length:\n",
    "                            hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "                        hex_array = [hex_str[i:i+4] for i in range(0, len(hex_str), 4)]\n",
    "\n",
    "                        byte_vocab.update(hex_array)\n",
    "\n",
    "byte_list = list(byte_vocab)\n",
    "print(len(byte_list))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 16:03:44,584 - root - INFO - Processing test.pcap\n",
      "2024-12-17 16:08:57,656 - root - INFO - Processing train_val_split_2\n",
      "2024-12-17 16:08:57,661 - root - INFO - Processing train_val_split_2 train.parquet\n",
      "2024-12-17 16:08:57,662 - root - INFO - Processing train_val_split_2 val.pcap\n",
      "2024-12-17 16:10:18,305 - root - INFO - Processing train_val_split_2 train.pcap\n",
      "2024-12-17 16:18:06,987 - root - INFO - Processing train_val_split_2 val.parquet\n",
      "2024-12-17 16:18:06,990 - root - INFO - Processing train_val_split_0\n",
      "2024-12-17 16:18:06,992 - root - INFO - Processing train_val_split_0 train.parquet\n",
      "2024-12-17 16:18:06,992 - root - INFO - Processing train_val_split_0 val.pcap\n",
      "2024-12-17 16:19:29,644 - root - INFO - Processing train_val_split_0 train.pcap\n",
      "2024-12-17 16:27:37,387 - root - INFO - Processing train_val_split_0 val.parquet\n",
      "2024-12-17 16:27:37,390 - root - INFO - Processing train_val_split_1\n",
      "2024-12-17 16:27:37,393 - root - INFO - Processing train_val_split_1 train.parquet\n",
      "2024-12-17 16:27:37,393 - root - INFO - Processing train_val_split_1 val.pcap\n",
      "2024-12-17 16:29:01,858 - root - INFO - Processing train_val_split_1 train.pcap\n",
      "2024-12-17 16:36:06,123 - root - INFO - Processing train_val_split_1 val.parquet\n",
      "2024-12-17 16:36:06,125 - root - INFO - Processing test.parquet\n",
      "2024-12-17 16:36:06,126 - root - INFO - Finished\n"
     ]
    }
   ],
   "source": [
    "# # file/{test.pcap} or file/{train_val_split_0}/{train.pcap}\n",
    "def write2csv(type, data, label):\n",
    "    file_path = f'{output_path}/raw/{type}.csv'\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        with open(file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(list([str(i) for i in range(int(max_payload_length/4))]) + ['class'])\n",
    "\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data + [label])\n",
    "\n",
    "\n",
    "for type in os.listdir(dataset_path):\n",
    "    logger.info(f'Processing {type}')\n",
    "    if 'test' in type: \n",
    "        if 'pcap' in type:\n",
    "            packets = scapy.PcapReader(f'{dataset_path}/{type}')\n",
    "            data_frame = pd.read_parquet(f'{dataset_path}/{type[:-5]}.parquet')\n",
    "\n",
    "            def process_packet(packet, id):\n",
    "                packet = clean_packet(packet)\n",
    "                if packet == 0:\n",
    "                    return None\n",
    "                \n",
    "                hex_str = bytes(packet).hex()\n",
    "                if len(hex_str) < max_payload_length:\n",
    "                    hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "                hex_array = [byte_list.index(hex_str[i:i+4]) for i in range(0, len(hex_str), 4)]\n",
    "                return (hex_array, data_frame.iloc[id]['class_str'])\n",
    "\n",
    "            with Pool(cpu_count()) as pool:\n",
    "                results = pool.starmap(process_packet, [(packet, id) for id, packet in enumerate(packets)])\n",
    "                \n",
    "            for result in results:\n",
    "                if result is not None:\n",
    "                    write2csv(type[:-5], result[0], result[1])\n",
    "    else:\n",
    "        for class_id, file_name in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "            logger.info(f'Processing {type} {file_name}')\n",
    "            if 'pcap' in file_name:\n",
    "                packets =  scapy.PcapReader(f'{dataset_path}/{type}/{file_name}')\n",
    "                data_frame = pd.read_parquet(f'{dataset_path}/{type}/{file_name[:-5]}.parquet')\n",
    "                \n",
    "                def process_packet(packet, id):\n",
    "                    packet = clean_packet(packet)\n",
    "                    if packet == 0:\n",
    "                        return None\n",
    "                    \n",
    "                    hex_str = bytes(packet).hex()\n",
    "                    if len(hex_str) < max_payload_length:\n",
    "                        hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "                    hex_array = [byte_list.index(hex_str[i:i+4]) for i in range(0, len(hex_str), 4)]\n",
    "                    return (hex_array, data_frame.iloc[id]['class_str'])\n",
    "\n",
    "                with Pool(cpu_count()) as pool:\n",
    "                    results = pool.starmap(process_packet, [(packet, id) for id, packet in enumerate(packets)])\n",
    "                    \n",
    "                for result in results:\n",
    "                    if result is not None:\n",
    "                        write2csv(f'{type}/{file_name[:-5]}', result[0], result[1])\n",
    "        \n",
    "logger.info('Finished')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 09:38:25,036 - root - INFO - Processing train_val_split_2\n",
      "2025-01-06 09:38:25,038 - root - INFO - Processing train_val_split_2 train\n",
      "2025-01-06 09:40:50,212 - root - INFO - Processing train_val_split_2 val\n",
      "2025-01-06 09:41:17,693 - root - INFO - Processing train_val_split_0\n",
      "2025-01-06 09:41:17,695 - root - INFO - Processing train_val_split_0 train\n",
      "2025-01-06 09:43:44,559 - root - INFO - Processing train_val_split_0 val\n",
      "2025-01-06 09:44:13,135 - root - INFO - Processing test\n",
      "2025-01-06 09:44:13,137 - root - INFO - Processing test malware.pcap\n",
      "2025-01-06 09:50:06,155 - root - INFO - Processing test benign.pcap\n",
      "2025-01-06 10:02:07,116 - root - INFO - Processing train_val_split_1\n",
      "2025-01-06 10:02:07,119 - root - INFO - Processing train_val_split_1 train\n",
      "2025-01-06 10:04:50,090 - root - INFO - Processing train_val_split_1 val\n",
      "2025-01-06 10:05:16,259 - root - INFO - Finished\n"
     ]
    }
   ],
   "source": [
    "# # file/test/{test.pcap} or file/train_val_split_0/{train/val}/.pcap\n",
    "def write2csv(type, data, label):\n",
    "    file_path = f'{output_path}/raw/{type}.csv'\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        with open(file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(list([str(i) for i in range(int(max_payload_length/4))]) + ['class'])\n",
    "\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data + [label])\n",
    "\n",
    "\n",
    "for type in os.listdir(dataset_path):\n",
    "    logger.info(f'Processing {type}')\n",
    "\n",
    "    if 'test' == type:\n",
    "        for class_id, file_name in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "            if 'pcap' in file_name:\n",
    "                logger.info(f'Processing {type} {file_name}')\n",
    "\n",
    "                def process_packet(packet, id):\n",
    "                    packet = clean_packet(packet)\n",
    "                    if packet == 0:\n",
    "                        return None\n",
    "                    \n",
    "                    hex_str = bytes(packet).hex()\n",
    "                    if len(hex_str) < max_payload_length:\n",
    "                        hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "                    hex_array = [byte_list.index(hex_str[i:i+4]) for i in range(0, len(hex_str), 4)]\n",
    "                    return (hex_array, file_name)\n",
    "\n",
    "                packets =  scapy.PcapReader(f'{dataset_path}/{type}/{file_name}')\n",
    "                with Pool(cpu_count()) as pool:\n",
    "                    results = pool.starmap(process_packet, [(packet, id) for id, packet in enumerate(packets)])\n",
    "                    \n",
    "                for result in results:\n",
    "                    if result is not None:\n",
    "                        write2csv(type, result[0], result[1])\n",
    "    else:\n",
    "        for class_id, folder in enumerate(os.listdir(f'{dataset_path}/{type}')):\n",
    "            logger.info(f'Processing {type} {folder}')\n",
    "\n",
    "            for file_name in os.listdir(f'{dataset_path}/{type}/{folder}'):\n",
    "                if 'pcap' in file_name:\n",
    "                    def process_packet(packet, id):\n",
    "                        packet = clean_packet(packet)\n",
    "                        if packet == 0:\n",
    "                            return None\n",
    "                        \n",
    "                        hex_str = bytes(packet).hex()\n",
    "                        if len(hex_str) < max_payload_length:\n",
    "                            hex_str = hex_str + '0' * (max_payload_length - len(hex_str))\n",
    "                        hex_array = [byte_list.index(hex_str[i:i+4]) for i in range(0, len(hex_str), 4)]\n",
    "                        return (hex_array, file_name)\n",
    "                    \n",
    "                    packets =  scapy.PcapReader(f'{dataset_path}/{type}/{folder}/{file_name}')\n",
    "                    with Pool(cpu_count()) as pool:\n",
    "                        results = pool.starmap(process_packet, [(packet, id) for id, packet in enumerate(packets)])\n",
    "                        \n",
    "                    for result in results:\n",
    "                        if result is not None:\n",
    "                            write2csv(f'{type}/{folder}', result[0], result[1])\n",
    "        \n",
    "logger.info('Finished')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_process]",
   "language": "python",
   "name": "conda-env-data_process-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
