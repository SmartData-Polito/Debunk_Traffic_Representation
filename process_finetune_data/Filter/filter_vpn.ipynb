{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For filter \n",
    "\n",
    "* use ISCXVPN as a demo\n",
    "* Statistic many pkts information\n",
    "* Filter many unrelated protocols\n",
    "* VPN - {VPN/NoVPN}/{pcap}\n",
    "* TLS - {Benigh/Malware}/{pcap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import scapy.all as scapy\n",
    "import scapy.contrib.igmp as igmp\n",
    "import scapy.contrib.igmpv3 as igmpv3\n",
    "from collections import defaultdict\n",
    "\n",
    "os.chdir('LLM4Traffic/tool/Filter')\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(       \n",
    "    level=logging.INFO,            \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  \n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/filter_vpn.log', mode='w'),  \n",
    "        logging.StreamHandler()          \n",
    "    ],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'external_pcaps/ISCX-VPN-2016'\n",
    "output_path = 'external_pcaps/ISCX-VPN-2016/Filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_to_csv(data, filename, csv_path):\n",
    "    # Check if the CSV file already exists\n",
    "    if os.path.exists(csv_path):\n",
    "        # Load the existing CSV file\n",
    "        df_existing = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        # Create an empty DataFrame if the CSV file does not exist\n",
    "        df_existing = pd.DataFrame()\n",
    "\n",
    "    df_new = pd.DataFrame([{'filename' : filename}])\n",
    "    df_new = df_new.assign(**data)\n",
    "\n",
    "    # Combine the existing DataFrame with the new DataFrame\n",
    "    df_combined = pd.concat([df_existing, df_new])\n",
    "    df_combined = df_combined.fillna(0)\n",
    "    df_combined.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = {\n",
    "    'network_management_protocols': ['icmp', 'icmpv6', 'dhcp', 'dhcpv6', 'igmp', 'snmp', 'arp', 'cops'],\n",
    "    'nat_protocols': ['nat-pmp', 'rsip'],\n",
    "    'route_management_protocols': ['db-lsp', 'db-lsp-disc', 'pathport', 'stp', 'bfd_echo', 'bgp', 'ecmp'],\n",
    "    'service_management_protocols': ['ssdp', 'lldp', 'srvloc', 'ipxsap', 'opa', 'cbsp'],\n",
    "    'link-local_protocols': ['llmnr', 'nbns', 'mdns', 'lsd'],\n",
    "    'link_management_protocols': ['llc'],\n",
    "    'distributed_protocols': ['thrift', 'dcerpc', 'rmi'],\n",
    "    'real_time_protocols': ['rtcp', 'stun'],\n",
    "    'remote_access_protocols': ['vnc', 'x11', 'msnms'],\n",
    "    'network_time_protocols': ['ntp'],\n",
    "    'security_protocols': ['ocsp', 'pkix-cert', 'egd', 'chargen', 'tpm', 'knet'],\n",
    "    'industrial_protocols': ['r-goose', 'dcp-pft', 'dcp-af', 'nxp_802154_sniffer', 'enip', 'c1222', 'ax4000'],\n",
    "    'file_protocols': ['lanman', 'bjnp', 'spoolss', 'ndps', 'laplink', 'bzr', 'cvspserver'],\n",
    "    'quake_protocols': ['quake', 'quake2', 'quake3', 'quakeworld'],\n",
    "    'iot_management_protocols': ['bat.vis', 'tplink-smarthome', 'coap','mqtt'],\n",
    "    'mobile_protocols': ['gsm_ipa'],\n",
    "    'database_protocols': ['tds']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# statistics pcap infomation\n",
    "def statistics_pcap(pcap_path):\n",
    "    command = f\"tshark -r {pcap_path} -T fields -e _ws.col.Protocol | sort | uniq -c | sort -nr\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    # Process the output\n",
    "    lines = result.stdout.strip().split('\\n')\n",
    "    protocol_counts = {}\n",
    "\n",
    "    for line in lines:\n",
    "        count, protocol = line.strip().split(maxsplit=1)\n",
    "        protocol_counts[protocol] = int(count)\n",
    "\n",
    "    return protocol_counts\n",
    "\n",
    "def filter_pcap(pcap_path, output_path):\n",
    "    rule = \"\"\n",
    "    for type in protocols:\n",
    "        for protocol in protocols[type]:\n",
    "            rule += f\"not {protocol} and \"\n",
    "    rule = rule[:-5]\n",
    "    \n",
    "    command = f'tshark -r {pcap_path} -Y \"{rule}\" -w {output_path}'\n",
    "    subprocess.run(command, shell=True, capture_output=True, text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def process_folder(folder):\n",
    "    if folder == 'Filtered':\n",
    "        return\n",
    "\n",
    "    logger.info(f\"Processing folder: {folder}\")\n",
    "    for file in os.listdir(f'{data_path}/{folder}'):\n",
    "        logger.info(f\"Processing file: {file}\")\n",
    "\n",
    "        filter_pcap(f'{data_path}/{folder}/{file}', f'{output_path}/Raw/{file}')\n",
    "\n",
    "# Get the list of folders to process\n",
    "folders_to_process = [folder for folder in os.listdir(data_path) if folder != 'Filtered']\n",
    "\n",
    "# Use multiprocessing to process each folder in parallel\n",
    "with Pool(cpu_count()) as pool:\n",
    "    pool.map(process_folder, folders_to_process)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics the protocol counts\n",
    "# seperate the pcap filter and statistics, just for acceleration\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    if folder == 'Filtered':\n",
    "        continue\n",
    "\n",
    "    logger.info(f\"Processing folder: {folder}\")\n",
    "    for file in os.listdir(f'{data_path}/{folder}'):\n",
    "        logger.info(f\"Processing file: {file}\")\n",
    "\n",
    "        # Statistics the protocol counts\n",
    "        origin_protocol_counts = statistics_pcap(f'{data_path}/{folder}/{file}')\n",
    "        save_to_csv(origin_protocol_counts, file, f'./results/raw_protocol_counts.csv')\n",
    "        logger.info(f\"Original packets {folder}/{file}: {origin_protocol_counts}\")\n",
    "\n",
    "        filtered_protocol_counts = statistics_pcap(f'{output_path}/Raw/{file}')\n",
    "        save_to_csv(filtered_protocol_counts, file, f'./results/filtered_protocol_counts.csv')\n",
    "        logger.info(f\"Filtered packets {folder}/{file}: {filtered_protocol_counts}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_process]",
   "language": "python",
   "name": "conda-env-data_process-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
