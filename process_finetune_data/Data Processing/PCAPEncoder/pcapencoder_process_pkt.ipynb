{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "process et-bert data for fine-tuning\n",
    "label.pcap (tsv format) -> train/validation/test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import scapy.all as scapy\n",
    "import random\n",
    "import binascii\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'vpn-app'\n",
    "\n",
    "dataset_path = f'{dataset}'\n",
    "output_path = f'code/PCAP_encoder/1.Datasets/Classification/{dataset}'\n",
    "output_withoutIP_path = f'code/PCAP_encoder/1.Datasets/Classification/without_IP/{dataset}'\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "os.makedirs(output_withoutIP_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_packet(packet):\n",
    "    if packet.haslayer(scapy.Ether):\n",
    "        packet = packet[scapy.Ether].payload\n",
    "\n",
    "    if packet.haslayer(scapy.IP):\n",
    "        packet[scapy.IP].src = \"0.0.0.0\"\n",
    "        packet[scapy.IP].dst = \"0.0.0.0\"\n",
    "    elif packet.haslayer('IPv6'):\n",
    "        packet['IPv6'].src = \"::\"\n",
    "        packet['IPv6'].dst = \"::\"\n",
    "\n",
    "    if packet.haslayer(scapy.UDP):\n",
    "        packet[scapy.UDP].sport = 0 \n",
    "        packet[scapy.UDP].dport = 0  \n",
    "    elif packet.haslayer(scapy.TCP):\n",
    "        packet[scapy.TCP].sport = 0  \n",
    "        packet[scapy.TCP].dport = 0  \n",
    "    \n",
    "    return packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_json = f'./{dataset}.json'\n",
    "class_indexs = json.load(open(mapping_json, 'r'))\n",
    "\n",
    "def group_string_by_n(pkt, n=4):\n",
    "    s = binascii.hexlify(bytes(pkt)).decode()\n",
    "    return ' '.join(s[i:i+n] for i in range(0, len(s), n))\n",
    "\n",
    "for split_folder in os.listdir(dataset_path):\n",
    "    print(f\"Processing file: {split_folder}\")\n",
    "    if split_folder == 'test':\n",
    "        dataset_file = [['question', 'class', 'type_q', 'context']]\n",
    "        for file in os.listdir(f\"{dataset_path}/{split_folder}\"):\n",
    "            if file.endswith('.pcap'):\n",
    "                print(f\"Processing file: {file}\")\n",
    "                with scapy.PcapReader(f\"{dataset_path}/{split_folder}/{file}\") as pkt_reader:\n",
    "                    for pkt in pkt_reader:\n",
    "                        pkt = clean_packet(pkt)\n",
    "                        context = group_string_by_n(pkt)\n",
    "                        dataset_file.append(['What is the representation of this packet?', class_indexs[file[:-5]], file[:-5], context])\n",
    "        os.makedirs(f\"{output_withoutIP_path}\", exist_ok=True)\n",
    "        output_dataframe = pd.DataFrame(dataset_file[1:], columns=dataset_file[0])\n",
    "        output_dataframe.to_parquet(f\"{output_withoutIP_path}/{split_folder}.parquet\", index=False)\n",
    "    else:\n",
    "        for type in os.listdir(f\"{dataset_path}/{split_folder}\"):\n",
    "            dataset_file = [['question', 'class', 'type_q', 'context']]\n",
    "            for file in os.listdir(f\"{dataset_path}/{split_folder}/{type}\"):\n",
    "                if file.endswith('.pcap'):\n",
    "                    print(f\"Processing file: {file}\")\n",
    "                    with scapy.PcapReader(f\"{dataset_path}/{split_folder}/{type}/{file}\") as pkt_reader:\n",
    "                        for pkt in pkt_reader:\n",
    "                            pkt = clean_packet(pkt)\n",
    "                            context = group_string_by_n(pkt)\n",
    "                            dataset_file.append(['What is the representation of this packet?', class_indexs[file[:-5]], file[:-5], context])\n",
    "            \n",
    "            os.makedirs(f\"{output_withoutIP_path}/{split_folder}\", exist_ok=True)\n",
    "            output_dataframe = pd.DataFrame(dataset_file[1:], columns=dataset_file[0])\n",
    "            output_dataframe.to_parquet(f\"{output_withoutIP_path}/{split_folder}/{type}.parquet\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_process]",
   "language": "python",
   "name": "conda-env-data_process-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
